---
layout: "../../../layouts/PostsLayout.astro"
capitolo: 2
esercizi: "prova"
---

# Probabilit√† condizionata

Vogliamo calcolare la probabilit√† che tengano conto di _informazioni parziali_ sull'esito dell'esperimento.

Cosa si intende con _informazioni parziali_. Per spiegarlo facciamo un esperimento:

_lancio 2 dadi_ (con il concetto che posso distinguerli, per esempio uno √® rosso o e blu. In questo caso scegliamo l'ordine)

Cosa vuol dire informazioni parziali?<br/>
In questo caso potrebbe essere: "la somma fa 9"

$\Omega = \{ (i,j) \}$ con `i` = lancio il primo dado, `j` = lancio il secondo. $i,j = \{ 1,2,3,4,5,6 \}$

$\#\Omega = 36$

$\mathbb P(A) = \frac{\#A}{\#\Omega} = \frac{4}{36} = \frac{1}{9}$

$A = \{ (4,5), (5,4), (3,6), (6,3) \}$

---

$B =$ "il primo dado ha dato 6"

$\mathbb P(B) = \frac{6}{36} = \frac{1}{6}$

---

Ora immaginiamo che un omino ci dica che vedendo che con il primo esca 6. Ora quante probabilit√† ci sono che la sua somma faccia 9?

Le informazioni parziali delle _condizioni_ nel quale noi dobbiamo creare una nuova $\mathbb P$. Come notazione per indicare la nuova $\mathbb P$ si indica con $\mathbb P(A | B)$ che significa: "la $\mathbb P$ dato $B$". Spiegato a parole: "calcolare la probabilit√† dell'evento di $A$ con la condizione di $B$"

:::def
Dato $(\Omega, \mathbb P)$ e $B$ _evento_ definisco probabilit√† condizionata a $B$. Indico con $\mathbb P(* | B)$ la seguente funzione:

$$
\mathbb P(* |B): \mathbb P(\Omega) \longrightarrow \Omega \qquad A -> \mathbb P(A | B) = \frac{\mathbb P(A \cap B)}{\mathbb P(B)}
$$

a patto che:

$$
\frac{
\mathbb P(B)}{0}
$$

:::

ü™∂ probabilit√† condizionata $\mathbb P(A‚à£B)$, che si legge ‚Äúprobabilit√† di $A$ condizionata da $B$‚Äù

Continuando l'esempio:

$P(A \cap B) = \frac{\#A \cap B}{\# \Omega} = \frac{1}{36}$

$A \cap B = \{ (6,3) \}$

$\mathbb P(B) = \frac{6}{36}$

$\mathbb (A|B) = \frac{\mathbb P(A \cap B)}{\mathbb P(B)} = \frac{1}{6}$

$C =$ "il primo dado ha fatto 1"

$$
\mathbb P(A |C) = \frac{A \cap C}{\mathbb P} = \frac{0}{\frac{6}{36}} = 0
$$

---

## La probabilit√† condizionata √® ben definita?

Per scoprirlo dobbiamo vedere che le 3 regole della probabilit√† valgano.

1. _La $\mathbb P(A | B) \geq 0$_? $\forall A \mathbb P(A | B) = \frac{\mathbb P(A unito b)}{\mathbb P(B) \geq 0}$

2. $\mathbb P(\Omega | B) = 1$ (la somma di tutte le partizioni risulter√† 1)?<br/>
   $\mathbb P(\Omega | B)= \frac{\Omega \cap B}{\mathbb P(B)} = \frac{\mathbb P(B)}{\mathbb P(B)} = 1$

3. $A_1$ e $A_2$ con $A_2$ intersecato $A_1 = \emptyset$ (la legge dei singoletti) $\mathbb P(A_1 \cap A_2 | B) = \mathbb P(A_1 | B) + \mathbb P(a_2 | B)$? Dato che $A_1$ e $A_2$ sono disgiunti anche l'intersezione con $\mathbb B$ sar√† disgiunta.

Il punto √® che prima avevo $(\Omega, \mathbb P)$ ho definito una nuova misura di probabilit√† su $\Omega$ che ho chiamato $\mathbb P(* | B)$

osservazione:

$$
\mathbb P(A | B) = \frac{\mathbb P(A \cap B)}{\mathbb P(B)}
$$

$$
\mathbb P(B) \cdot \mathbb P(A | B) = \mathbb P(B) \cdot \frac{\mathbb P(A \cap B)}{\mathbb P(B)}
$$

$$
(*)\qquad \mathbb P(A \cap B) = \mathbb P(A | B) \cdot \mathbb P(B)
$$

regola generalizzata: **regola della moltiplicazione**

Per 3 eventi: $A_1, A_2, A_3$

(\*\*) $\mathbb P(A_1 \cup A_2 \cup A_3) = \mathbb P(A_3 | A_1 \cap A_2) \cdot \mathbb P(A_2 | A_1) \cdot \mathbb P(A_1)$

Appello a (\*) con:

$A = A_3$

$B = A_1 \cap A_2$

$\mathbb P(A_3 \cap A_1 \cap A_2) = \mathbb P(A_3 | A_1 \cap A_2) \cdot \mathbb (A_1 \cap A_2)$

## Formula delle probabilit√† totali

:::def
Dato $(A)^n_{i = 2}$ partizione di $\Omega$

$\mathbb P(B) = \Sigma^2_{i = 2} \mathbb (B \cap Ai) = \Sigma \mathbb (B|Ai) \cdot \mathbb P(A_i)$
:::

Il risultato del nostro calcolo delle probabilit√† √® un insieme formato da insiemi a due a due disgiunti. Se voglio calcolare l'unione con la nuova formula posso usare quella sopraindicata.

ü™ô In soldoni: hai due o pi√π eventi e vuoi sapere qual √® il loro valore sommato.

## :d[Teorema di Bayes]

Dati $A$ e $B$ eventi:

$$
    \mathbb P(A|B) = \frac{\mathbb P(B|A) \cdot \mathbb P(A)}{\mathbb P(B)} = \frac{\mathbb P(B \cap A)}{\mathbb P(B)} = \frac{\mathbb P(B|A) \mathbb P(A)}{\mathbb P(B)}
$$

Se gli $(Ai)^n_{i = 2}$ sono partizione di $\Omega$

$$
 \mathbb P(Ai | B) = \frac{\mathbb P(B|Ai)\mathbb (Ai)}{\sigma^n_{i=i} \mathbb P(B|Ai) \mathbb (Ai)}
$$

Serve a "invertire" il

## Esercizi

_lancio una moneta equa 3 volte. Sia $A$ l'evento "escono pi√π teste che croci" e sia $B$ l'evento "il primo lancio restituisce testa". <br/> Calcolare la probabilit√† di $A$ e la probabilit√† di $A$ dato $B$_

$A =$ "escono pi√π teste che croci"

$\Omega = \{ (w_1, w_2, w_3) \quad w_i \in \{ t,c \} \}$

$\#\Omega = 2^3 = 8$

Posso usare l'uniforme discreta perch√© la moneta √® equa e $\Omega$ √® finita

$\mathbb P(A) = \frac{\#A}{\#\Omega} = \frac{4}{8} = \frac{1}{2}$

---

B

$$
\mathbb P(A|B)= \frac{\mathbb P(A \cap B)}{\mathbb P(B)} = \frac{\frac{\#A \cap B}{\# \Omega}}{\frac{\#B}{\#\Omega}}= \frac{3}{4}
$$

---

### Esercizio 2

_Estraggo 3 carte da un mazzo regolare di 52 senza reibussolamento.<br/> Calcolare la probabilit√† che nessuna delle 3 carte sia di cuori_

13 carte per seme. Semi = `Quadri, Cuori, Pichhe, Fiori`.

Ci sono due vie: **in blocco** e **successive**. In blocco: prendo 3 carte insieme, successive: ci sar√† una prima estrazione, poi una seconda e cos√¨ via.

#### Risoluzione in blocco

$A =$ non ci sono cuori

$$
\mathbb P(A) = \frac{\binom{39}{3} \binom{13}{0}}{\binom{52}{3}} = \frac{\binom{19}{3}}{\binom{52}{3}}
$$

Da notare $\binom{13}{0}$ che significa "prendo 0 carte (di cuori) da 13 carte totali (di cuori)"

### Estrazioni successive

Usando le probabilit√† condizionate posso risolvere questo problema.

$A =$ "non estraggo cuori"

$A_1 =$ "non estraggo cuori alla prima estrazione"

$A_2 =$ = "...."

$A= A_1 \cap A_2 \cap A_3$ da intersecare perch√® nella prima estrazione non _ti interessa_ cosa ci sar√† nella seconda estrazione e nella seconda non _ti interessa_ la terza estrazione e cos√¨ via, per formare un sottoinsieme del genere bisogna intersecare.

Prima estrazione:

$$
\mathbb (A_1) = \binom{39}{52}
$$

39 sono tutte le carte escluse quelle di cuori.

Seconda estrazione:

Se alla prima √® uscito un non cuori allora la $\mathbb P$ di $A_2$ √®:

$$
\mathbb P(A_2 | A_1) = \binom{38}{51}
$$

Per calcolare $\mathbb P(A_2)$ posso usare le forumle delle $\mathbb P$ totali?

Dato che √® $A_1$ e $A_1^c$ sono partizione di $\Omega$? La risposta √® si.

Ora riscrivo la formula della probabilit√† totale:

$$
\mathbb P(A_2) = \mathbb P(A_2 | A_2) \mathbb P(A)

\\

\mathbb P(A_1 \cap A_2 \cap A_3) =\\
 P(A_3 | A_1 \cap A_2)\cdot \mathbb P(A_2 | A_1) \cdot \mathbb (A_1) =\\
  \binom{37}{50} \cdot \binom{38}{51} \cdot \binom{39}{52}
$$

### Esercizio 3

_lancio un dado a 4 facce. Se esce 1 o 2 lo lancio di nuovo altrimenti mi fermo. Calcolare la probabilit√† che la somma dei numeri ottenuti sia almeno 4._

L'esercizio √® diviso in 2:

1. "lancio un dado a 4 facce"
2. "se esce 1 o 2 continuo se esce di pi√π mi fermo"

#### Primo modo

$\Omega = \{ (1,2), (1,2), (1,3), (1,4), (2.1), (2,2), (2,3), (2,4), (3,0), (4,0) \}$ $0=$ "non lancio il dado la seconda volta

Posso usare la $\mathbb P$ uniforme discreta?

1. $\#\Omega$ finita? ‚úÖ
2. I singoletti (i punti di $\Omega$) sono equi possibili? ‚ùå perch√® mi aspetto che $(1,1) e (3,0)$ non escano con la stessa frequenza

Devo costruire la $\mathbb P$ e non sa√† uniforme discreta.

$A_1$ = "esce `1` al primo lancio" = $\Omega = \{ (1,1), (1,2), (1,3), (1,4) \}$

$A_2$ = "esce `2` al secondo lancio" = $\Omega = \{ (2,1), (2,2), (2,3), (2,4) \}$

....

3. Equit√† $\mathbb P(A_1)$ e $\mathbb P(A_2)$ e $\mathbb P(A_3)$ e $\mathbb P(A_4) = \mathbb P(\Omega)$

Dato che $\mathbb P(\Omega) = 1$ e gli elementi che lo formano sono 4 ogni singoletto avr√† valore $\frac{1}{4}$

Mi mancano le $\mathbb P$ dei singoletti in $A_1$ e $A_2$:

Osserviamo che nella $\mathbb P(A_1) = \frac{1}{4} = \mathbb P(\{ (1,1), (1,2), (1,3), (1,4) \} )$ data l'equita del dado mi aspetto che l'equit√† di $\mathbb P(\{ (1,1) \}) = \mathbb P()$
TODO FINIRE LA FORMULA

Ma allora sto cercando che 4 numeri che sommati valgono $\mathbb P(\{ (4,1) \}) =\frac{1}{4} = \frac{1}{16}$ stesso ragionamento per tti gli altri singoletti.

Ora hai la $\mathbb P$ perch√® so quanto vale ogni singoletto.

Ora abbiamo $\Omega$ e $\mathbb P$ possiamo procedere alla risoluzione dell'evento:

$A=$ "la somma deve valere almeno 4" <br/>
$A = \{ (1,3), (1,4), (2,2), (2,3),(2,4), (4,0) \}$

$\mathbb P(A) = (\{ (1,3) \} \cup \{ (1,4) \} \cup ...)$
$= 5 \cdot \frac{1}{16} + \frac{1}{4} = \frac{9}{16}$

#### Secondo metodo

La parte che la probabilit√† che con $A_i$ √® $\frac{1}{4}$ Se suppongo $\mathbb P(A | A_1) = \frac{2}{4} = \frac{1}{2}$

$\mathbb P(A | A_2) = \frac{3}{4}$ <br/>
$\mathbb P(A | A_3) = 0$

$\mathbb P(A| A_4) = 1$

Usando la formula delle $\mathbb P$ totali.

$\mathbb P(A)= \mathbb P(A|A_1) \mathbb P(A_2)+ \mathbb P(A| A_2)+ ...$
TODO finire formula

:::att
Le $(A_i)^{4}_{i =1}$ √® una partizione di $\Omega$
:::

### Esercizio 3

_Un test √® 99% efficace nel rilvare una certa malattia quando il soggetto √® effetivamnete malato. Tuttavia restituisce un falso positivo nel 2% dei casi quando la malattia non √® presente. <br/> Supponendo che la malattia sia presente nel 5% della popolazione, qual √® la probabilit√† di essere malato se si √® risultati positivi al test?_

$M=$ "il soggetto √® malato"

$M^C=$ "Il soggetto √® sano"

$P =$ "il test √® positivo"

$P^C =$ "il test √® negativo"

$\mathbb P(P | M) = 0.99$ "il test 99%" (traduzione in simboli del testo)

$\mathbb P(P | M^C) = 0.02$ "il 2% dei casi quando la malattia non √® presente"

$\mathbb P(M) = 0.05$ probabilit√† di testare un malato

$\mathbb P(M | P) = ?$ "Qual √® la probabilit√† di essere malato se si √® risultati positivi al test?"

Teorema di bays = "la prob di $\mathbb P(A |B) = \frac{\mathbb P(B|A)\mathbb P(A)}{\mathbb P(B)}$"

$\mathbb P(M|P) = \frac{\mathbb P(P|M)\mathbb P(M)}{\mathbb P(P)}$

TODO finire

$$
= \frac{0.99 \cdot 0.005}{0.99 \cdot 0.05 + 0.02 \cdot 0.95} = 0.7226
$$

### Esercizio 4

_Ognuna di 3 urne contiene $b$ palline bianche ed $n$ palline nere. Prendo a casa una pallina dalla prima urna e la metto nella seconda. Poi prendo una pallina dalla seconda e la metto nella 3. Infine prendo una pallina dalla terza urna. Calcolare la probabilit√† di estrarre una pallina Bianca alla terza estrazione. Confrontarla con la probabilit√† di estrarre una pallina bianca alla prima estrazione e con la probabilit√† di estrarre una pallina bianca alla seconda estrazione._

$\Omega = \{ (w_1,w_2,w_3) \} \qquad wi \in \{ B,N \}$

$A =$ "la terza estrazione √® Bianca"
$=\{ (w_1,w_2, B) \qquad w_i \in \{ B,N \} \}$

Uso le $\mathbb P$ condizionate. Che condizionanti prendo? / come partiziono $\Omega$?

$A_2 =$ "la 2¬∞ estrazione √® BIANCA"

$A_1 =$ "la 1¬∞ estrazione √® BIANCA"

$$
A_1 \cap A_2 \\
A_2 \cap A^c_2 \\
A_1^C \cap A_2 \\
A^C_1 \cap A_2^C
$$

$\mathbb P(A_3 | A_1 \cap A_2) = \frac{b+1}{b+n+1}$

$\mathbb P(A_3 | A_2^C) = \frac{b}{b+n+1}$

$\mathbb P(A_3 | A_1^C \cap A_2) = \frac{b+1}{b+n+1}$

$\mathbb P(A_3 | A_1^C \cap A_2^c) = \frac{b}{b+n+1}$

Uso la formula della $\mathbb P$ totali per calcolare $\mathbb P(A_3)$

$$
P(A_3) =  \\
\mathbb P(A_3 | A_1 \cap A_2) \cdot \mathbb P(A_1 \cap A_2) \\
\mathbb P(A_3 | A_1 \cap A_2^C) \cdot \mathbb P(A_1 \cap A_2^C) \\
\mathbb P(A_3 | A_1^C \cap A_2) \cdot \mathbb P(A_1^C \cap A_2) \\
\mathbb P(A_3 | A_1^C \cap A_2^C) \cdot \mathbb P(A_1^C \cap A_2^C) \\
$$

Uso la regola della moltiplicazione: che mi dice che se devi calcolare la probabilit√† di

$$
\mathbb P(A_1 \cap A_2) = \mathbb P(A_2 |  A_1) \mathbb P(A_1) = \frac{b+1}{b+n+1}
$$

le probabilit√† delle intersezioni le reisco a calcolare.

$\mathbb P(A_1 \cap A_2^C) = \mathbb P(A_2^C |  A_1) \cdot \mathbb P(A_1) = \frac{b}{b+n} \cdot \frac{n}{b+n+1}$

$\mathbb P(A_1^C \cap A_2) = \mathbb P(A_2 |  A_1^C) \cdot \mathbb P(A_1^C) = \frac{b}{b+n+1} \cdot \frac{n}{b+n}$

$\mathbb P(A_1^C \cap A_2^C) = \mathbb P(A_2^C |  A_1^C) \cdot \mathbb P(A_1^C) = \frac{n}{b+n} \cdot \frac{n+1}{b+n+1}$

$\mathbb P(A_3) = \frac{b}{b+n} = \mathbb P(A_1)$

$\mathbb P(A_2) = \frac{b}{b+n}$
