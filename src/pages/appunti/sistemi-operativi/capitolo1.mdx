---
capitolo: 1
layout: "../../../layouts/PostsLayout.astro"
---

# Che cos'√® un sistema operativo

Non esiste una vera e propria definizione di sistema operativo per via della sua vastit√†; in generale
un sistema operativo √® il solo programma che funziona sempre nel calcolatore, chiamato **kernel**.
Spesso per√≤ il kernel √® affiancato ad altri programmi, come la GUI presente in Windows e non in Linux, questi si chiamano
**programmi di sistema** e sono associati al sistema operativo. I programmi di sistema non fanno parte necessariamente del kernel.

Infine un sistema operativo pu√≤ possedere dei **programmi applicativi** che non sono correlati al funzionamento di quest'ultimo.

Oggigiorno molti nei sistemi operativi mobili non sono costituiti solo da un kernel ma anche da un **middleware**, ovvero da una collezione
di ambienti software che fornisce servizi aggiuntivi per chi
sviluppa applicazioni. Per esempio, entrambi i principali sistemi operativi per dispositivi mobili (iOS di Apple e Android di Google) oltre a un kernel di base dispongono di un middleware che supporta (tra l‚Äôaltro) database, multimedialit√† e grafica.

# Interruzioni

Le interruzioni devo aggiungerlo

## üìù Gerarchia delle memorie 1.2.2

Ci sono due tipi di memoria:

1. La **memoria principale** chiamata anche RAM, √® la memoria indirizzata direttamente dalle istruzioni eseguite dalla CPU. √à una memoria volatile cio√® che perde i dati una volta spenta la macchina

2. La **memoria secondaria** √® il luogo in cui risiedono permanentemente le informazioni ovvero se spengo il PC alla riaccensione i miei dati ci saranno ancora.

![Gerarchia Memoria](https://storage.googleapis.com/pubblico-sito-edoardo/gerarchia.png)

La gerarchia delle memorie sono dalle pi√π veloci alle pi√π lente. Le memorie pi√π capienti sono pi√π lente üêå, le memorie veloci sono meno capienti e pi√π costoseü§ëü´∞.

Ci sono poi delle memorie velocissime ma piccole piccola come la memoria cache e i registri che si parla di decimi di nanosecondi, tutte e due sono memorie volatili.

## Il concetto di caching 1.8.3

La tecnologia con i suoi limiti non permette di avere per esempio 500 GB di registri.
Le memoria hanno una scala di gerarchia √® la memoria "che sta pi√π in alto" funge da cache a quella pi√π in basso. Esempio (la RAM fa da cache per l'ssd)

Per capire come mai non possiamo aumentare a sproposito i numeri dei registri facciamo una piccola digressione parlando di come sia fatta una memoria RAM.
Ci sono due modi di implementare la RAM statica e dinamica:
nella ram dinamica c'√® un condensatore che si carica e si scarica. In circa due secondi il condensatore si scarica e di conseguenza non sappiamo pi√π se fosse carico o scarico (quindi o 0 o 1), dato che noi abbiamo bisogno di tenere vivo il dato il PC aggiorna il valore del condensatore ogni due secondi (circa). I personal computer hanno tutti la memoria dinamica. Per costruirla servono 1 transistor e 1 condensatore.

I registri usano il concetto della memoria statica. La ram statica usa il funzionamento dei flip flip nel quale servono 6 transistor: occupa pi√π spazio e costa di pi√π. Questa √® la ragione per cui conviene usarne di meno ma in maniera pi√π efficiente.

Ecco spiegato il motivo per il quale abbiamo una gerarchia all'interno del PC.

Un altro motivo: ogni dispositivo input/output (immaginiamo una tastiera) parla attraverso il controller il quale √® regolato da un piccolo semplice processore esso si chiamato buffer. Il SO interagisce con il controller attraverso un software apposito noto come driver del dispositivo.
Per avviare un operazione il sistema operativo tramite il driver.

Questo tipo di connessione non va bene per le memorie con tantissime informazioni, questi vengono spostare a blocchi di 1024,2048,4096 blocchi. Per efficienza la ram non coinvolge troppo il SO c'√® un canale chiamate "direct memory access" (**DMA**).

## Multitasking e Time-sharing

Quando lanciamo unn programma -> il sistema operativo lo copia in RAM -> "fa partire il programma". In questa operazione notiamo che il sistema operativo ci vuole rendere la vita semplice perch√© noi non dobbiamo sapere dove il programma √® salvato.

Immaginiamo che ci sia gi√† un programma in esecuzione e questo ha bisogno una pausa di 10ms. **Il sistema operativo invece che lasciare la CPU inoccupata la usa per un'altro programma**. Questo √® il concetto di multiprogrammazione (multitasking). Quando un programma si ferma temporaneamente, il sistema operativa ha gi√† in RAM un altro programma a cui assegnare la CPU. Come se ci fosse una coda per la CPU. Un po' come nell'immagine qui sotto (ma un po' pi√π velocemente)

![persone in coda che rappresentano i programmi](https://c.tenor.com/9QhYEwBkNwYAAAAd/line-up-kasabian.gif)

---

Alcune applicazione degli unenti sono **interattive** (come un editor di testo), cio√® aspetta che l'utente faccia qualcosa. Ci sono anche sistemi pi√π utenti. Ma cosa succede se il programma "√® in attesa"? La CPU √® sempre occupata?
Ovviamente no gli ingegneri hanno trovato una soluzione: il **time-sharing** cio√® l'idea di distribuire il tempo della CPU (ad esempio ogni 10ms) cos√¨ da dare una impressione di simultaneit√†. In questo modo pi√π programmi possono girare "contemporaneamente"

Questa √® una semplificazione ci sono alcuni problemi che dobbiamo affrontare.

## Come un programma si protegge

### Duplice modalit√† di funzionamento

Nei moderni processori le istruzioni possono essere di due modalit√†: con privilegi e no. Ci sono istruzioni delicate che possono essere eseguite solo dal sistema operativo le **operazioni di sistema**. I programmi degli utenti possono chiedere di fare delle system calls, una system calls provoca un'eccezione.
Quando chiamiamo un system call viene modificato il bit di modalit√† il che comporta poter eseguire istruzioni privilegiate, quando termina l'istruzione privilegiata il bit di sistema viene rimesso a 0. <br/>
Si dice spesso che si usa il codice in **kernel mode**. Istruzioni potenzialmente pericolose non possono essere eseguite dall'utente.

### Timer

Immaginiamo un ciclo infinito, come liberare la CPU? Con il **timer hardware**. Il sistema operativa fa partire un timer che al termine della sua scadenza fa partire un'altro programma. per esempio se si hanno 10ms il programma 1 usa 10ms poi passa al programma 2 e cos√¨ via.

Quando il timer scade manda una System Call. Questo principio √® il **time sharing**.

### Protezione della memoria

Cosa succede se un programma modifica i dati di un altro programma o ancora peggio quello del sistema operativo.

Ci sono due registri dedicati alla memorizzazione della base e la fine della porzione di memoria dell'area della ram dedicata al programma. Se il programma prova a modificare una porzione fuori da quell'area l'hardware glielo impedir√†.

Concettualmente √® cos√¨, i pc moderni hanno una sofisticatezza maggiore.

## Riassunto

I sistemi operativi sono dei **mediatori** tra l'hardware e il software. I sistemi operativi si evolvo.
